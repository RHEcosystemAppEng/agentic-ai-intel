{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f33fe3f9-ec38-45a7-bccc-184d713a28b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "import os\n",
    "import time\n",
    "import boto3\n",
    "import botocore\n",
    "from pathlib import Path\n",
    "from huggingface_hub import notebook_login\n",
    "from huggingface_hub import login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aa562aeb-f9d1-46c4-bbc3-1ef07eebe66f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d060a4a4c6674572a007f223ebbd0412",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Some models require a hugginface login; uncomment the following code\n",
    "#to enable an interactive login screen where you can provide your hugginface credentials\n",
    "#from huggingface_hub import notebook_login.\n",
    "#For some models, you may also need to login to Huggingface using your browser and agree to a use policy.\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0458485-3545-4f26-8cac-28a0f35a5ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setup variables for this script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "54eafdfc-ed71-4b2d-9d80-af6b49ff4bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_dir = Path.cwd() / \"models\"\n",
    "models_dir.mkdir(parents=True, exist_ok=True)\n",
    "model_prefix = \"meta-llama\"\n",
    "model_name = \"Llama-3.1-8B-Instruct\"\n",
    "full_model_name = f\"{model_prefix}/{model_name}\"\n",
    "save_path = models_dir / model_prefix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7fa6d5f8-3e33-434e-a82a-f1eff98b5106",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Download model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a5573117-e883-4177-95cd-64228bcde136",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a1159d0a82a4c02827a9e77a474d53b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 17 files:   0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd9ccd9315b54146a3eb20b4af1e8e2b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       ".gitattributes:   0%|          | 0.00/1.52k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48da5bb4ade7411aba30cbde21cad358",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/855 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7bd7a2a289db4a78aa18fd18cf122dce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00004.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bbb9ee10566149c48679a24b06e81bad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00004-of-00004.safetensors:   0%|          | 0.00/1.17G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14a5b88267734d89b91589bf3f365808",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "USE_POLICY.md:   0%|          | 0.00/4.69k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7929289114684ec196bfea982c0edb79",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00003-of-00004.safetensors:   0%|          | 0.00/4.92G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "410915731dc147a994d579ad96ae60b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00004.safetensors:   0%|          | 0.00/4.98G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15c0922210ba4bb5a6fb40c4495405ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/184 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61045753237346adbe49076001485066",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "original/consolidated.00.pth:   0%|          | 0.00/16.1G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7ab91f642814937aa1d804d4d4a40ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json:   0%|          | 0.00/23.9k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "722695bd948c4b1ea55280baf67f7222",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "params.json:   0%|          | 0.00/199 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a75c02c864a64aad8bd5bda9e3051690",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "original/tokenizer.model:   0%|          | 0.00/2.18M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c664b6bb22c44bd2bf4aa4e097f4353a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/296 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13412da0a361446fa9a4b274184f16d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/9.09M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad89d3e5ea6349089ab2ed4d6bc3bf73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/55.4k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'/opt/app-root/src/agentic-ai-intel/workbench-source/models/meta-llama'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from huggingface_hub import snapshot_download\n",
    "snapshot_download(repo_id=full_model_name, local_dir=save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a76fda51-1c97-4137-83b2-2bd1d1fce059",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the s3 connection parameters (these are entered in the workbench setup screens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ab9e3c08-dc1a-4dfb-8b80-b5a7d4ea6647",
   "metadata": {},
   "outputs": [],
   "source": [
    "aws_access_key_id = os.environ.get('AWS_ACCESS_KEY_ID')\n",
    "aws_secret_access_key = os.environ.get('AWS_SECRET_ACCESS_KEY')\n",
    "endpoint_url = os.environ.get('AWS_S3_ENDPOINT')\n",
    "region_name = os.environ.get('AWS_DEFAULT_REGION')\n",
    "bucket_name = os.environ.get('AWS_S3_BUCKET')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5493ed36",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08da7c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create the models bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b4b4449",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_client = boto3.client(\n",
    "    's3',\n",
    "    endpoint_url=endpoint_url,\n",
    "    aws_access_key_id=aws_access_key_id,\n",
    "    aws_secret_access_key=aws_secret_access_key,\n",
    "    region_name=region_name \n",
    ")\n",
    "s3_client.create_bucket(Bucket=bucket_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "668f6aa9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7903a87d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prepare to upload the model to the s3 bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "608592ff-749c-4ede-9abe-84c235c002f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "session = boto3.session.Session(\n",
    "            aws_access_key_id=aws_access_key_id,\n",
    "            aws_secret_access_key=aws_secret_access_key\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "70089f9d-1ff9-4c16-bd84-93ee1c5c0df0",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_resource = session.resource(\n",
    "               's3',\n",
    "               config=botocore.client.Config(signature_version='s3v4'),\n",
    "               endpoint_url=endpoint_url,\n",
    "               region_name=region_name\n",
    "              )\n",
    "bucket = s3_resource.Bucket(bucket_name)\n",
    "                        \n",
    "def upload_directory_to_s3(local_directory, s3_prefix):\n",
    "    for root, dirs, files in os.walk(local_directory):\n",
    "        for filename in files:\n",
    "            file_path = os.path.join(root, filename)\n",
    "            relative_path = os.path.relpath(file_path, local_directory)\n",
    "            s3_key = os.path.join(s3_prefix, relative_path)\n",
    "            print(f\"{file_path} -> {s3_key}\")\n",
    "            bucket.upload_file(file_path, s3_key)\n",
    "                                \n",
    "def list_objects(prefix):\n",
    "    filter = bucket.objects.filter(Prefix=prefix)\n",
    "    for obj in filter.all():\n",
    "        print(obj.key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "812d26bb-32d1-40ae-8919-14b3a3b02511",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Upload the model to an S3 bucket within the cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ef6fa2a0-481d-451d-91b4-3d7fbbf005cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/app-root/src/agentic-ai-intel/workbench-source/models/meta-llama/README.md -> Llama-3.1-8B-Instruct/README.md\n",
      "/opt/app-root/src/agentic-ai-intel/workbench-source/models/meta-llama/LICENSE -> Llama-3.1-8B-Instruct/LICENSE\n",
      "/opt/app-root/src/agentic-ai-intel/workbench-source/models/meta-llama/config.json -> Llama-3.1-8B-Instruct/config.json\n",
      "/opt/app-root/src/agentic-ai-intel/workbench-source/models/meta-llama/USE_POLICY.md -> Llama-3.1-8B-Instruct/USE_POLICY.md\n",
      "/opt/app-root/src/agentic-ai-intel/workbench-source/models/meta-llama/.gitattributes -> Llama-3.1-8B-Instruct/.gitattributes\n",
      "/opt/app-root/src/agentic-ai-intel/workbench-source/models/meta-llama/generation_config.json -> Llama-3.1-8B-Instruct/generation_config.json\n",
      "/opt/app-root/src/agentic-ai-intel/workbench-source/models/meta-llama/model.safetensors.index.json -> Llama-3.1-8B-Instruct/model.safetensors.index.json\n",
      "/opt/app-root/src/agentic-ai-intel/workbench-source/models/meta-llama/special_tokens_map.json -> Llama-3.1-8B-Instruct/special_tokens_map.json\n",
      "/opt/app-root/src/agentic-ai-intel/workbench-source/models/meta-llama/tokenizer_config.json -> Llama-3.1-8B-Instruct/tokenizer_config.json\n",
      "/opt/app-root/src/agentic-ai-intel/workbench-source/models/meta-llama/tokenizer.json -> Llama-3.1-8B-Instruct/tokenizer.json\n",
      "/opt/app-root/src/agentic-ai-intel/workbench-source/models/meta-llama/model-00004-of-00004.safetensors -> Llama-3.1-8B-Instruct/model-00004-of-00004.safetensors\n",
      "/opt/app-root/src/agentic-ai-intel/workbench-source/models/meta-llama/model-00003-of-00004.safetensors -> Llama-3.1-8B-Instruct/model-00003-of-00004.safetensors\n",
      "/opt/app-root/src/agentic-ai-intel/workbench-source/models/meta-llama/model-00002-of-00004.safetensors -> Llama-3.1-8B-Instruct/model-00002-of-00004.safetensors\n",
      "/opt/app-root/src/agentic-ai-intel/workbench-source/models/meta-llama/model-00001-of-00004.safetensors -> Llama-3.1-8B-Instruct/model-00001-of-00004.safetensors\n",
      "/opt/app-root/src/agentic-ai-intel/workbench-source/models/meta-llama/.cache/huggingface/.gitignore -> Llama-3.1-8B-Instruct/.cache/huggingface/.gitignore\n",
      "/opt/app-root/src/agentic-ai-intel/workbench-source/models/meta-llama/.cache/huggingface/download/generation_config.json.lock -> Llama-3.1-8B-Instruct/.cache/huggingface/download/generation_config.json.lock\n",
      "/opt/app-root/src/agentic-ai-intel/workbench-source/models/meta-llama/.cache/huggingface/download/config.json.lock -> Llama-3.1-8B-Instruct/.cache/huggingface/download/config.json.lock\n",
      "/opt/app-root/src/agentic-ai-intel/workbench-source/models/meta-llama/.cache/huggingface/download/USE_POLICY.md.lock -> Llama-3.1-8B-Instruct/.cache/huggingface/download/USE_POLICY.md.lock\n",
      "/opt/app-root/src/agentic-ai-intel/workbench-source/models/meta-llama/.cache/huggingface/download/model-00001-of-00004.safetensors.lock -> Llama-3.1-8B-Instruct/.cache/huggingface/download/model-00001-of-00004.safetensors.lock\n",
      "/opt/app-root/src/agentic-ai-intel/workbench-source/models/meta-llama/.cache/huggingface/download/README.md.lock -> Llama-3.1-8B-Instruct/.cache/huggingface/download/README.md.lock\n",
      "/opt/app-root/src/agentic-ai-intel/workbench-source/models/meta-llama/.cache/huggingface/download/model-00002-of-00004.safetensors.lock -> Llama-3.1-8B-Instruct/.cache/huggingface/download/model-00002-of-00004.safetensors.lock\n",
      "/opt/app-root/src/agentic-ai-intel/workbench-source/models/meta-llama/.cache/huggingface/download/LICENSE.lock -> Llama-3.1-8B-Instruct/.cache/huggingface/download/LICENSE.lock\n",
      "/opt/app-root/src/agentic-ai-intel/workbench-source/models/meta-llama/.cache/huggingface/download/.gitattributes.lock -> Llama-3.1-8B-Instruct/.cache/huggingface/download/.gitattributes.lock\n",
      "/opt/app-root/src/agentic-ai-intel/workbench-source/models/meta-llama/.cache/huggingface/download/model-00003-of-00004.safetensors.lock -> Llama-3.1-8B-Instruct/.cache/huggingface/download/model-00003-of-00004.safetensors.lock\n",
      "/opt/app-root/src/agentic-ai-intel/workbench-source/models/meta-llama/.cache/huggingface/download/model-00004-of-00004.safetensors.lock -> Llama-3.1-8B-Instruct/.cache/huggingface/download/model-00004-of-00004.safetensors.lock\n",
      "/opt/app-root/src/agentic-ai-intel/workbench-source/models/meta-llama/.cache/huggingface/download/model.safetensors.index.json.lock -> Llama-3.1-8B-Instruct/.cache/huggingface/download/model.safetensors.index.json.lock\n",
      "/opt/app-root/src/agentic-ai-intel/workbench-source/models/meta-llama/.cache/huggingface/download/README.md.metadata -> Llama-3.1-8B-Instruct/.cache/huggingface/download/README.md.metadata\n",
      "/opt/app-root/src/agentic-ai-intel/workbench-source/models/meta-llama/.cache/huggingface/download/LICENSE.metadata -> Llama-3.1-8B-Instruct/.cache/huggingface/download/LICENSE.metadata\n",
      "/opt/app-root/src/agentic-ai-intel/workbench-source/models/meta-llama/.cache/huggingface/download/config.json.metadata -> Llama-3.1-8B-Instruct/.cache/huggingface/download/config.json.metadata\n",
      "/opt/app-root/src/agentic-ai-intel/workbench-source/models/meta-llama/.cache/huggingface/download/USE_POLICY.md.metadata -> Llama-3.1-8B-Instruct/.cache/huggingface/download/USE_POLICY.md.metadata\n",
      "/opt/app-root/src/agentic-ai-intel/workbench-source/models/meta-llama/.cache/huggingface/download/.gitattributes.metadata -> Llama-3.1-8B-Instruct/.cache/huggingface/download/.gitattributes.metadata\n",
      "/opt/app-root/src/agentic-ai-intel/workbench-source/models/meta-llama/.cache/huggingface/download/generation_config.json.metadata -> Llama-3.1-8B-Instruct/.cache/huggingface/download/generation_config.json.metadata\n",
      "/opt/app-root/src/agentic-ai-intel/workbench-source/models/meta-llama/.cache/huggingface/download/model.safetensors.index.json.metadata -> Llama-3.1-8B-Instruct/.cache/huggingface/download/model.safetensors.index.json.metadata\n",
      "/opt/app-root/src/agentic-ai-intel/workbench-source/models/meta-llama/.cache/huggingface/download/special_tokens_map.json.lock -> Llama-3.1-8B-Instruct/.cache/huggingface/download/special_tokens_map.json.lock\n",
      "/opt/app-root/src/agentic-ai-intel/workbench-source/models/meta-llama/.cache/huggingface/download/tokenizer.json.lock -> Llama-3.1-8B-Instruct/.cache/huggingface/download/tokenizer.json.lock\n",
      "/opt/app-root/src/agentic-ai-intel/workbench-source/models/meta-llama/.cache/huggingface/download/special_tokens_map.json.metadata -> Llama-3.1-8B-Instruct/.cache/huggingface/download/special_tokens_map.json.metadata\n",
      "/opt/app-root/src/agentic-ai-intel/workbench-source/models/meta-llama/.cache/huggingface/download/tokenizer_config.json.lock -> Llama-3.1-8B-Instruct/.cache/huggingface/download/tokenizer_config.json.lock\n",
      "/opt/app-root/src/agentic-ai-intel/workbench-source/models/meta-llama/.cache/huggingface/download/tokenizer_config.json.metadata -> Llama-3.1-8B-Instruct/.cache/huggingface/download/tokenizer_config.json.metadata\n",
      "/opt/app-root/src/agentic-ai-intel/workbench-source/models/meta-llama/.cache/huggingface/download/tokenizer.json.metadata -> Llama-3.1-8B-Instruct/.cache/huggingface/download/tokenizer.json.metadata\n",
      "/opt/app-root/src/agentic-ai-intel/workbench-source/models/meta-llama/.cache/huggingface/download/model-00004-of-00004.safetensors.metadata -> Llama-3.1-8B-Instruct/.cache/huggingface/download/model-00004-of-00004.safetensors.metadata\n",
      "/opt/app-root/src/agentic-ai-intel/workbench-source/models/meta-llama/.cache/huggingface/download/model-00003-of-00004.safetensors.metadata -> Llama-3.1-8B-Instruct/.cache/huggingface/download/model-00003-of-00004.safetensors.metadata\n",
      "/opt/app-root/src/agentic-ai-intel/workbench-source/models/meta-llama/.cache/huggingface/download/model-00002-of-00004.safetensors.metadata -> Llama-3.1-8B-Instruct/.cache/huggingface/download/model-00002-of-00004.safetensors.metadata\n",
      "/opt/app-root/src/agentic-ai-intel/workbench-source/models/meta-llama/.cache/huggingface/download/model-00001-of-00004.safetensors.metadata -> Llama-3.1-8B-Instruct/.cache/huggingface/download/model-00001-of-00004.safetensors.metadata\n",
      "/opt/app-root/src/agentic-ai-intel/workbench-source/models/meta-llama/.cache/huggingface/download/original/consolidated.00.pth.lock -> Llama-3.1-8B-Instruct/.cache/huggingface/download/original/consolidated.00.pth.lock\n",
      "/opt/app-root/src/agentic-ai-intel/workbench-source/models/meta-llama/.cache/huggingface/download/original/params.json.lock -> Llama-3.1-8B-Instruct/.cache/huggingface/download/original/params.json.lock\n",
      "/opt/app-root/src/agentic-ai-intel/workbench-source/models/meta-llama/.cache/huggingface/download/original/tokenizer.model.lock -> Llama-3.1-8B-Instruct/.cache/huggingface/download/original/tokenizer.model.lock\n",
      "/opt/app-root/src/agentic-ai-intel/workbench-source/models/meta-llama/.cache/huggingface/download/original/params.json.metadata -> Llama-3.1-8B-Instruct/.cache/huggingface/download/original/params.json.metadata\n",
      "/opt/app-root/src/agentic-ai-intel/workbench-source/models/meta-llama/.cache/huggingface/download/original/tokenizer.model.metadata -> Llama-3.1-8B-Instruct/.cache/huggingface/download/original/tokenizer.model.metadata\n",
      "/opt/app-root/src/agentic-ai-intel/workbench-source/models/meta-llama/.cache/huggingface/download/original/consolidated.00.pth.metadata -> Llama-3.1-8B-Instruct/.cache/huggingface/download/original/consolidated.00.pth.metadata\n",
      "/opt/app-root/src/agentic-ai-intel/workbench-source/models/meta-llama/original/params.json -> Llama-3.1-8B-Instruct/original/params.json\n",
      "/opt/app-root/src/agentic-ai-intel/workbench-source/models/meta-llama/original/tokenizer.model -> Llama-3.1-8B-Instruct/original/tokenizer.model\n",
      "/opt/app-root/src/agentic-ai-intel/workbench-source/models/meta-llama/original/consolidated.00.pth -> Llama-3.1-8B-Instruct/original/consolidated.00.pth\n"
     ]
    }
   ],
   "source": [
    "upload_directory_to_s3(save_path, model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0e25272-d563-4fa0-a0be-e05e82a2dbba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
